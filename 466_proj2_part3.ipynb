{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "466-proj2-part3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrmMsb__sNQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "FILE = \"committee_utterances.tsv\"\n",
        "path = \"drive/My Drive/Colab Notebooks/466-proj2/\"\n",
        "\n",
        "df = pd.read_csv(path + FILE, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTyifS_sAX8H",
        "colab_type": "text"
      },
      "source": [
        "##Prepare dataset\n",
        "Get a subset of the data to include records from only the top N speakers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2d0ff8UubrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine First and last name\n",
        "names = []\n",
        "for index,row in df.iterrows():\n",
        "    speaker = row['last'] + \" \" + row['first']\n",
        "    names.append(speaker)\n",
        "\n",
        "# add to dataframe\n",
        "df[\"full_name\"] = names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sggC_NCGveyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# top 100 speakers with the most records in the dataframe\n",
        "top_100_speakers = df.pivot_table(index=['full_name'], aggfunc='size')\n",
        "top_100_speakers = df.groupby(['full_name'])['full_name']\\\n",
        "                .count()\\\n",
        "                .reset_index(name='count')\\\n",
        "                .sort_values(['count'], ascending=False)\\\n",
        "                .head(100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9IQzoPy6-n8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_top_100 = df[df.full_name.isin(top_100_speakers['full_name'])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcvpml-K90WN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "d52ef26e-5617-44c0-e629-839163498d7f"
      },
      "source": [
        "N = 50\n",
        "\n",
        "speaker_utter_cnt = []\n",
        "for name in top_100_speakers.full_name:\n",
        "    temp_df = df_top_100[df_top_100.full_name == name]\n",
        "\n",
        "    tot_words = 0\n",
        "    for t in temp_df.text:\n",
        "        tot_words += len(t.split())\n",
        "\n",
        "    speaker_utter_cnt.append((name, tot_words))\n",
        "speaker_utter_cnt.sort(key=lambda tup: tup[1], reverse=True)    \n",
        "\n",
        "top_N_speakers = [tup[0] for tup in speaker_utter_cnt[:N]]\n",
        "df_top_N = df_top_100[df_top_100.full_name.isin(top_N_speakers)]\n",
        "\n",
        "print(\"Total speakers: \", N)\n",
        "print(\"(First, the top 100 speakers were chosen based on number of records in the dataset.\")\n",
        "print(\"Then, we narrowed down the selection to the top \", N, \" speakers based on number of utterances.)\")\n",
        "print()"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total speakers:  50\n",
            "(First, the top 100 speakers were chosen based on number of records in the dataset.\n",
            "Then, we narrowed down the selection to the top  50  speakers based on number of utterances.)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8F2cMM_GS4i",
        "colab_type": "text"
      },
      "source": [
        "##Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkn6GazEG6FP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "b1539e52-1e2b-499f-e104-412a75a883ca"
      },
      "source": [
        "\n",
        "import nltk, random, spacy\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')    #these are only for Collab, on Frank the \"download\"is not necessary\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('tagsets') \n",
        "nltk.download('punkt')\n",
        "\n",
        "stemmer = nltk.stem.porter.PorterStemmer() #NLTK's built-in stemmer resource\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "#uses NLTK's built in word tokenizer. Output is a list now.\n",
        "def myTokenizer(text):\n",
        "  return nltk.word_tokenize(text)\n",
        "\n",
        "#POS tagger.\n",
        "#input is a list of words, output is a list of tuples (Word, Tag)\n",
        "##Do you want to know what the tags mean? Run this: nltk.help.upenn_tagset()\n",
        "def getPOS(tokenized):\n",
        "  return nltk.pos_tag(tokenized)\n",
        "\n",
        "#This removes all the stop words, and actually also punctuation and non-alphabetic words, and makes all lower case\n",
        "#you can edit your own version\n",
        "def filterTokens(tokenized):\n",
        "  return [token.lower() for token in tokenized if token.isalpha() and token.lower() not in stopwords.words('english')]\n",
        "\n",
        "#Using the NLTK stemmer\n",
        "def stemming(tokenized):\n",
        "  return [stemmer.stem(token) for token in tokenized]\n",
        "\n",
        "def lemmatize(tokenized):\n",
        "    doc = nlp(' '.join(tokenized))\n",
        "    return [token.lemma_ for token in doc]\n",
        "\n",
        "# text is lemmatized, filtered, and tokenized\n",
        "def mostCommon(texts, N):\n",
        "    vocab = []\n",
        "    for text in texts:\n",
        "        tokenized = lemmatize(filterTokens(myTokenizer(text)))\n",
        "        vocab.extend(tokenized)\n",
        "    \n",
        "    freqdist = nltk.FreqDist(vocab) \n",
        "    freqdist = freqdist.most_common()\n",
        "    return freqdist[:N]\n",
        "\n",
        "def processWords(tokenized):\n",
        "    vocab = {}\n",
        "    for token in tokenized:\n",
        "        vocab[token] = True\n",
        "    return vocab\n",
        "\n",
        "def processSents(text):  # return [(sent, word_count)]\n",
        "    sents = sent_tokenizer.tokenize(text)\n",
        "    return [(sent, len(sent.split())) for sent in sents]\n",
        "\n",
        "def getEntities(text):\n",
        "    doc = nlp(text)\n",
        "    \n",
        "    summary = {}\n",
        "    entities = {}\n",
        "    # orgs = []\n",
        "    # persons = []\n",
        "    # gpes = []\n",
        "    # other = []\n",
        "    for ent in doc.ents:\n",
        "        # 1 build summary of all entities\n",
        "        if ent in summary:\n",
        "            summary[\"ent_cnt(\" + ent.label_ + \")\"] += 1\n",
        "        else:\n",
        "            summary[\"ent_cnt(\" + ent.label_ + \")\"] = 1\n",
        "            \n",
        "        entities[\"contains_entity(\" + ent.text +\")\"] = True\n",
        "        # # 2 get list of orgs mentioned\n",
        "        # if (ent.label_ == 'ORG'):\n",
        "        #     orgs.append(ent.text)\n",
        "        # # 3 get list of people mentioned\n",
        "        # elif (ent.label_ == 'PERSON'):\n",
        "        #     persons.append(ent.text)\n",
        "        # elif (ent.label_ == 'GPE'):\n",
        "        #     gpes.append(ent.text)            \n",
        "        # else:\n",
        "        #     other.append(ent.text)\n",
        "    # return summary, orgs, persons, gpes, other\n",
        "    return summary, entities\n",
        "\n",
        "    \n",
        "# Extract features of a single text\n",
        "def processText(text):\n",
        "    features = {}\n",
        "\n",
        "    cleaned = lemmatize(filterTokens(myTokenizer(text)))        \n",
        "\n",
        "    if (PREPROCESS_STAGE):\n",
        "        svs = speakerVocabScore(cleaned, num_of_speakers, TOP_VOCAB)\n",
        "        features.update(svs)\n",
        "\n",
        "    # word features\n",
        "    words = processWords(cleaned)\n",
        "    features.update(words)\n",
        "\n",
        "    # sentence features\n",
        "    sent_lengths = [sent[1] for sent in processSents(text)]\n",
        "    avg_sent = sum(sent_lengths) / len(sent_lengths)\n",
        "    features['avg_sent'] = avg_sent\n",
        "\n",
        "    # entity features\n",
        "    summary, entities = getEntities(text)\n",
        "    features.update(summary)\n",
        "    features.update(entities)\n",
        "    \n",
        "    return features\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# Extract additional features using the training set\n",
        "# - this takes about 2 minutes to do\n",
        "# -------------------------------------------------------------------------\n",
        "# given a speaker and dataset, returns a list of corresponding texts\n",
        "def getSpeakerTexts(speaker, data):\n",
        "    print('Speaker ', speaker, ' - total texts: ', len(data[data.full_name == speaker]['text']))\n",
        "    return data[data.full_name == speaker]['text']\n",
        "\n",
        "# Process the train data and create more features\n",
        "def preprocessSpeakers(speakers, train_data, label_encoder):\n",
        "    if (PREPROCESS_STAGE == False):\n",
        "        return []\n",
        "\n",
        "    speakers_summary = []\n",
        "    for name in speakers:\n",
        "        texts = getSpeakerTexts(name, train_data)\n",
        "        most_common = mostCommon(texts, 25)\n",
        "        speakers_summary.append({\n",
        "                                'ID': label_encoder.transform([name])[0],\n",
        "                                'name':name,\n",
        "                                'top_N_vocab':[tup[0] for tup in most_common]\n",
        "        })\n",
        "\n",
        "    return speakers_summary\n",
        "\n",
        "# This feature requires a prebuilt summary of the speakers (See preprocessSpeakers(...))\n",
        "def speakerVocabScore(tokenized, num_speakers, vocab_lookup):    \n",
        "    if (PREPROCESS_STAGE == False):\n",
        "         return {}\n",
        "\n",
        "    score_table = {}    # {speaker_id : score}\n",
        "\n",
        "    # rally up score\n",
        "    for word in tokenized:\n",
        "        if word in vocab_lookup:                    # this word in the top vocab\n",
        "            for speakerID in vocab_lookup[word]:    # add score to the speaker\n",
        "                if speakerID in score_table:\n",
        "                    score_table[\"SVS_\" + str(speakerID)] += 1  # SVS - speaker_vocab score\n",
        "                else:\n",
        "                    score_table[\"SVS_\" + str(speakerID)] = 1\n",
        "    return score_table\n",
        "# -------------------------------------------------------------------------\n",
        "# -------------------------------------------------------------------------\n",
        "\n"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awLREm8whWGJ",
        "colab_type": "text"
      },
      "source": [
        "##Split training/testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvGE5dAGDHt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# train/test data will only be from the sample-size\n",
        "def split_train_test(data, splitpt, sample_size = 1.0):    \n",
        "    length = len(data)\n",
        "    rand_df = pd.DataFrame(np.random.randn(length,2))\n",
        "    msk = np.random.rand(len(rand_df)) < splitpt    \n",
        "\n",
        "    train = data[msk]\n",
        "    old_len = len(train)\n",
        "    train = train.sample(frac=sample_size, replace=False)    \n",
        "    # print(\"train: old_length = \", old_len, \" new_length = \", len(train))\n",
        "    \n",
        "    test = data[~msk]\n",
        "    old_len = len(test)\n",
        "    test = test.sample(frac=sample_size, replace=False)\n",
        "    # print(\"test: old_length = \", old_len, \" new_length = \", len(test))\n",
        "    return train, test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eefZboI4Bm3-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "5b62a7c4-c50e-4d96-bb04-9bbf744d7c85"
      },
      "source": [
        "# setup train/test dataframes - empty\n",
        "train_df = pd.DataFrame(columns = df_top_N.columns)\n",
        "test_df = pd.DataFrame(columns = df_top_N.columns)\n",
        "\n",
        "# add to train/test dataframes\n",
        "SAMPLE_SIZE = .25\n",
        "for name in top_N_speakers:\n",
        "    temp_df = df_top_N[df_top_N.full_name == name]  # only one speaker\n",
        "\n",
        "    train, test = split_train_test(temp_df, 0.8, SAMPLE_SIZE)\n",
        "    train_df = pd.concat([train_df, train])\n",
        "    test_df = pd.concat([test_df, test])\n",
        "\n",
        "print(\"Total points in dataset: \", len(df_top_N))\n",
        "print(\"Sample size: \", SAMPLE_SIZE)\n",
        "print(\"Total points in train: \", len(train_df))\n",
        "print(\"Total points in test: \", len(test_df))\n",
        "print(\"(For each speaker, their texts were split into 80% training and 20% testing)\")\n",
        "print()"
      ],
      "execution_count": 337,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total points in dataset:  12988\n",
            "Sample size:  0.25\n",
            "Total points in train:  2583\n",
            "Total points in test:  662\n",
            "(For each speaker, their texts were split into 80% training and 20% testing)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwKwjDKXGdcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelencoder = LabelEncoder()\n",
        "\n",
        "X_train = train_df['text']\n",
        "y_train = labelencoder.fit_transform(train_df['full_name'])\n",
        "\n",
        "X_test = test_df['text']\n",
        "y_test = labelencoder.transform(test_df['full_name'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odat-YNHcsb0",
        "colab_type": "text"
      },
      "source": [
        "##Pre-processing stage\n",
        "Extract features from the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Te8UhLRBpUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PREPROCESS_STAGE = False\n",
        "TOP_VOCAB = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPtaiqWBfiOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if (PREPROCESS_STAGE):\n",
        "    SPEAKER_SUMMARY = preprocessSpeakers(top_N_speakers, df_top_N, labelencoder)\n",
        "    num_of_speakers = len(SPEAKER_SUMMARY)\n",
        "\n",
        "    # save time checking if a word is in a speaker's top vocab with this\n",
        "    for i in range(0, num_of_speakers):\n",
        "        for word in SPEAKER_SUMMARY[i]['top_N_vocab']:\n",
        "            if word not in TOP_VOCAB:\n",
        "                TOP_VOCAB[word] = [SPEAKER_SUMMARY[i]['ID']]\n",
        "            else:\n",
        "                # print(word, \":\", TOP_VOCAB[word])\n",
        "                TOP_VOCAB[word].append(SPEAKER_SUMMARY[i]['ID'])            \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfxVjRFxpSNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample = \"And are the sole producer of 14 commodities in California. Including walnuts, which my family grows. And other products such as almonds and raisins. California's agricultural exports totaled $21 billion in 2013, representing 15% of the nation's total. What those figures show, is that farmers and ranchers are adapting.\"\n",
        "# processText(sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiVpR8tw3Wsa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "853f799a-984c-414a-f1d1-acd77df12931"
      },
      "source": [
        "### Vectorize features\n",
        "print(\"vectorizing...\", end = '')\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "vectorizer = DictVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(map(processText, list(X_train)))\n",
        "X_test_vec = vectorizer.transform(map(processText, list(X_test)))\n",
        "print(\"done\", )"
      ],
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vectorizing...done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwXQ1YJL3xNY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "264fe34a-51e1-4379-a1f4-ade7dba863a1"
      },
      "source": [
        "\n",
        "### Build model\n",
        "print(\"training model...\", end = '')\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB()\n",
        "model = model.fit(X_train_vec , y_train)\n",
        "\n",
        "print(\"done\", )"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training model...done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSyxJTZw3yUN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "c25570cb-eb06-4fae-e7d1-f9062c929dcf"
      },
      "source": [
        "\n",
        "### Accuracy Score\n",
        "print(\"====================================\")\n",
        "print(\"Evaluation Metrics\")\n",
        "print(\"====================================\")\n",
        "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
        "predicted = model.predict(X_test_vec)\n",
        "predicted_values = labelencoder.inverse_transform(predicted)\n",
        "true_values = labelencoder.inverse_transform(y_test)\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(true_values, predicted_values))\n",
        "print(\"precision: \")\n",
        "print(\"   (macro): \", precision_score(true_values, predicted_values, average='macro', zero_division=0))\n",
        "print(\"   (micro): \", precision_score(true_values, predicted_values, average='micro', zero_division=0))\n",
        "print(\"   (weighted): \", precision_score(true_values, predicted_values, average='weighted', zero_division=0))\n",
        "print(\"recall: \")\n",
        "print(\"   (macro): \", recall_score(true_values, predicted_values, average='macro'))\n",
        "print(\"   (micro): \", recall_score(true_values, predicted_values, average='micro'))\n",
        "print(\"   (weighted): \", recall_score(true_values, predicted_values, average='weighted'))\n",
        "print(\"f1 score:\")\n",
        "print(\"   (macro): \", f1_score(true_values, predicted_values, average='macro'))\n",
        "print(\"   (micro): \", f1_score(true_values, predicted_values, average='micro'))\n",
        "print(\"   (weighted): \", f1_score(true_values, predicted_values, average='weighted'))\n"
      ],
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===================\n",
            "Evaluation Metrics\n",
            "===================\n",
            "accuracy:  0.29607250755287007\n",
            "precision: \n",
            "   (macro):  0.18156064973715566\n",
            "   (micro):  0.29607250755287007\n",
            "   (weighted):  0.29692214549956963\n",
            "recall: \n",
            "   (macro):  0.14359679375801662\n",
            "   (micro):  0.29607250755287007\n",
            "   (weighted):  0.29607250755287007\n",
            "f1 score:\n",
            "   (macro):  0.12392008806978896\n",
            "   (micro):  0.29607250755287007\n",
            "   (weighted):  0.23594762946064943\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}