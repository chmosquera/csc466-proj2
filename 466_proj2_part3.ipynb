{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "466-proj2-part3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrmMsb__sNQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "FILE = \"committee_utterances.tsv\"\n",
        "path = \"drive/My Drive/Colab Notebooks/466-proj2/\"\n",
        "\n",
        "df = pd.read_csv(path + FILE, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTyifS_sAX8H",
        "colab_type": "text"
      },
      "source": [
        "##Prepare dataset\n",
        "Get a subset of the data to include records from only the top N speakers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2d0ff8UubrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine First and last name\n",
        "speaker+names = []\n",
        "for index,row in df.iterrows():\n",
        "    speaker = row['last'] + \" \" + row['first']\n",
        "    names.append(speaker)\n",
        "\n",
        "# add to dataframe\n",
        "df[\"full_name\"] = names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sggC_NCGveyl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "55f6b3c3-1f73-4891-bf07-7b9c2e6c6c5f"
      },
      "source": [
        "# top 100 speakers with the most records in the dataframe\n",
        "top_100_speakers = df.pivot_table(index=['full_name'], aggfunc='size')\n",
        "top_100_speakers = df.groupby(['full_name'])['full_name']\\\n",
        "                .count()\\\n",
        "                .reset_index(name='count')\\\n",
        "                .sort_values(['count'], ascending=False)\\\n",
        "                .head(100)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_name</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>891</th>\n",
              "      <td>Lara Ricardo</td>\n",
              "      <td>1061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1430</th>\n",
              "      <td>Secretary Committee</td>\n",
              "      <td>897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1119</th>\n",
              "      <td>Mullin Kevin</td>\n",
              "      <td>668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>716</th>\n",
              "      <td>Hernandez Ed</td>\n",
              "      <td>516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541</th>\n",
              "      <td>Frazier Jim</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>982</th>\n",
              "      <td>M. Randolph Liane</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1304</th>\n",
              "      <td>Ridley-Thomas Sebastian</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>Cabral Edgar</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Mahone Amber</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>Fanelli Susan</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    full_name  count\n",
              "891              Lara Ricardo   1061\n",
              "1430      Secretary Committee    897\n",
              "1119             Mullin Kevin    668\n",
              "716              Hernandez Ed    516\n",
              "541               Frazier Jim    500\n",
              "...                       ...    ...\n",
              "982         M. Randolph Liane     77\n",
              "1304  Ridley-Thomas Sebastian     76\n",
              "217              Cabral Edgar     75\n",
              "996              Mahone Amber     75\n",
              "493             Fanelli Susan     75\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9IQzoPy6-n8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_top_100 = df[df.full_name.isin(top_100_speakers['full_name'])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcvpml-K90WN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87bfde7c-14c3-46f8-d712-80af5381a8dd"
      },
      "source": [
        "N = 50\n",
        "\n",
        "speaker_utter_cnt = []\n",
        "for name in top_100_speakers.full_name:\n",
        "    temp_df = df_top_100[df_top_100.full_name == name]\n",
        "\n",
        "    tot_words = 0\n",
        "    for t in temp_df.text:\n",
        "        tot_words += len(t.split())\n",
        "\n",
        "    speaker_utter_cnt.append((name, tot_words))\n",
        "speaker_utter_cnt.sort(key=lambda tup: tup[1], reverse=True)    \n",
        "\n",
        "top_N_speakers = [tup[0] for tup in speaker_utter_cnt[:N]]\n",
        "df_top_N = df_top_100[df_top_100.full_name.isin(top_N_speakers)]\n",
        "df_top_N"
      ],
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vid</th>\n",
              "      <th>fileid</th>\n",
              "      <th>cid</th>\n",
              "      <th>c_name</th>\n",
              "      <th>c_house</th>\n",
              "      <th>hid</th>\n",
              "      <th>position</th>\n",
              "      <th>pid</th>\n",
              "      <th>diarization_id</th>\n",
              "      <th>last</th>\n",
              "      <th>first</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>utterance_order</th>\n",
              "      <th>text</th>\n",
              "      <th>full_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>4527</td>\n",
              "      <td>8xcAFOvPC50</td>\n",
              "      <td>2</td>\n",
              "      <td>Agriculture</td>\n",
              "      <td>Assembly</td>\n",
              "      <td>648</td>\n",
              "      <td>1</td>\n",
              "      <td>14987</td>\n",
              "      <td>4</td>\n",
              "      <td>Lund</td>\n",
              "      <td>Jay</td>\n",
              "      <td>844</td>\n",
              "      <td>857</td>\n",
              "      <td>48</td>\n",
              "      <td>Thank you very much for having me, it's a plea...</td>\n",
              "      <td>Lund Jay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>4527</td>\n",
              "      <td>8xcAFOvPC50</td>\n",
              "      <td>2</td>\n",
              "      <td>Agriculture</td>\n",
              "      <td>Assembly</td>\n",
              "      <td>648</td>\n",
              "      <td>1</td>\n",
              "      <td>14987</td>\n",
              "      <td>4</td>\n",
              "      <td>Lund</td>\n",
              "      <td>Jay</td>\n",
              "      <td>857</td>\n",
              "      <td>874</td>\n",
              "      <td>49</td>\n",
              "      <td>of this year on Economic Analysis of 2015 Drou...</td>\n",
              "      <td>Lund Jay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>4527</td>\n",
              "      <td>8xcAFOvPC50</td>\n",
              "      <td>2</td>\n",
              "      <td>Agriculture</td>\n",
              "      <td>Assembly</td>\n",
              "      <td>648</td>\n",
              "      <td>1</td>\n",
              "      <td>14987</td>\n",
              "      <td>4</td>\n",
              "      <td>Lund</td>\n",
              "      <td>Jay</td>\n",
              "      <td>875</td>\n",
              "      <td>897</td>\n",
              "      <td>50</td>\n",
              "      <td>It was done by a collection of agricultural ec...</td>\n",
              "      <td>Lund Jay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>4527</td>\n",
              "      <td>8xcAFOvPC50</td>\n",
              "      <td>2</td>\n",
              "      <td>Agriculture</td>\n",
              "      <td>Assembly</td>\n",
              "      <td>648</td>\n",
              "      <td>1</td>\n",
              "      <td>14987</td>\n",
              "      <td>4</td>\n",
              "      <td>Lund</td>\n",
              "      <td>Jay</td>\n",
              "      <td>897</td>\n",
              "      <td>918</td>\n",
              "      <td>51</td>\n",
              "      <td>We have a water year that starts October first...</td>\n",
              "      <td>Lund Jay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>4527</td>\n",
              "      <td>8xcAFOvPC50</td>\n",
              "      <td>2</td>\n",
              "      <td>Agriculture</td>\n",
              "      <td>Assembly</td>\n",
              "      <td>648</td>\n",
              "      <td>1</td>\n",
              "      <td>14987</td>\n",
              "      <td>4</td>\n",
              "      <td>Lund</td>\n",
              "      <td>Jay</td>\n",
              "      <td>918</td>\n",
              "      <td>943</td>\n",
              "      <td>52</td>\n",
              "      <td>four steps as each storm contributes water to ...</td>\n",
              "      <td>Lund Jay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30858</th>\n",
              "      <td>2858</td>\n",
              "      <td>nMgNQIdoyHs</td>\n",
              "      <td>148</td>\n",
              "      <td>Public Health and Developmental Services</td>\n",
              "      <td>Senate</td>\n",
              "      <td>497</td>\n",
              "      <td>4</td>\n",
              "      <td>103</td>\n",
              "      <td>1</td>\n",
              "      <td>Hernandez</td>\n",
              "      <td>Ed</td>\n",
              "      <td>1485</td>\n",
              "      <td>1494</td>\n",
              "      <td>555</td>\n",
              "      <td>Current vote count is 9-3, and that bill is ou...</td>\n",
              "      <td>Hernandez Ed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30859</th>\n",
              "      <td>2858</td>\n",
              "      <td>nMgNQIdoyHs</td>\n",
              "      <td>148</td>\n",
              "      <td>Public Health and Developmental Services</td>\n",
              "      <td>Senate</td>\n",
              "      <td>497</td>\n",
              "      <td>4</td>\n",
              "      <td>2998</td>\n",
              "      <td>4</td>\n",
              "      <td>Secretary</td>\n",
              "      <td>Committee</td>\n",
              "      <td>1494</td>\n",
              "      <td>1498</td>\n",
              "      <td>556</td>\n",
              "      <td>Anderson? Mitchell? (aye) Moorlach?</td>\n",
              "      <td>Secretary Committee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30860</th>\n",
              "      <td>2858</td>\n",
              "      <td>nMgNQIdoyHs</td>\n",
              "      <td>148</td>\n",
              "      <td>Public Health and Developmental Services</td>\n",
              "      <td>Senate</td>\n",
              "      <td>497</td>\n",
              "      <td>4</td>\n",
              "      <td>103</td>\n",
              "      <td>1</td>\n",
              "      <td>Hernandez</td>\n",
              "      <td>Ed</td>\n",
              "      <td>1504</td>\n",
              "      <td>1512</td>\n",
              "      <td>557</td>\n",
              "      <td>Current vote count is 9-2. That bill is out. I...</td>\n",
              "      <td>Hernandez Ed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30861</th>\n",
              "      <td>2858</td>\n",
              "      <td>nMgNQIdoyHs</td>\n",
              "      <td>148</td>\n",
              "      <td>Public Health and Developmental Services</td>\n",
              "      <td>Senate</td>\n",
              "      <td>497</td>\n",
              "      <td>4</td>\n",
              "      <td>2998</td>\n",
              "      <td>4</td>\n",
              "      <td>Secretary</td>\n",
              "      <td>Committee</td>\n",
              "      <td>1512</td>\n",
              "      <td>1521</td>\n",
              "      <td>558</td>\n",
              "      <td>Morrell? (no) Anderson? Mitchell? (aye) 9-3.</td>\n",
              "      <td>Secretary Committee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30862</th>\n",
              "      <td>2858</td>\n",
              "      <td>nMgNQIdoyHs</td>\n",
              "      <td>148</td>\n",
              "      <td>Public Health and Developmental Services</td>\n",
              "      <td>Senate</td>\n",
              "      <td>497</td>\n",
              "      <td>4</td>\n",
              "      <td>103</td>\n",
              "      <td>1</td>\n",
              "      <td>Hernandez</td>\n",
              "      <td>Ed</td>\n",
              "      <td>1521</td>\n",
              "      <td>1529</td>\n",
              "      <td>559</td>\n",
              "      <td>Current vote count is 9-3, that bill is out. T...</td>\n",
              "      <td>Hernandez Ed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12988 rows Ã— 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        vid  ...            full_name\n",
              "47     4527  ...             Lund Jay\n",
              "48     4527  ...             Lund Jay\n",
              "49     4527  ...             Lund Jay\n",
              "50     4527  ...             Lund Jay\n",
              "51     4527  ...             Lund Jay\n",
              "...     ...  ...                  ...\n",
              "30858  2858  ...         Hernandez Ed\n",
              "30859  2858  ...  Secretary Committee\n",
              "30860  2858  ...         Hernandez Ed\n",
              "30861  2858  ...  Secretary Committee\n",
              "30862  2858  ...         Hernandez Ed\n",
              "\n",
              "[12988 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8F2cMM_GS4i",
        "colab_type": "text"
      },
      "source": [
        "##Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkn6GazEG6FP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "f42dd96a-15ba-4ddf-fa14-0b3adf505a27"
      },
      "source": [
        "\n",
        "import nltk, random, spacy\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')    #these are only for Collab, on Frank the \"download\"is not necessary\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('tagsets') \n",
        "nltk.download('punkt')\n",
        "\n",
        "stemmer = nltk.stem.porter.PorterStemmer() #NLTK's built-in stemmer resource\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "#uses NLTK's built in word tokenizer. Output is a list now.\n",
        "def myTokenizer(text):\n",
        "  return nltk.word_tokenize(text)\n",
        "\n",
        "#POS tagger.\n",
        "#input is a list of words, output is a list of tuples (Word, Tag)\n",
        "##Do you want to know what the tags mean? Run this: nltk.help.upenn_tagset()\n",
        "def getPOS(tokenized):\n",
        "  return nltk.pos_tag(tokenized)\n",
        "\n",
        "#This removes all the stop words, and actually also punctuation and non-alphabetic words, and makes all lower case\n",
        "#you can edit your own version\n",
        "def filterTokens(tokenized):\n",
        "  return [token.lower() for token in tokenized if token.isalpha() and token.lower() not in stopwords.words('english')]\n",
        "\n",
        "#Using the NLTK stemmer\n",
        "def stemming(tokenized):\n",
        "  return [stemmer.stem(token) for token in tokenized]\n",
        "\n",
        "def lemmatize(tokenized):\n",
        "    doc = nlp(' '.join(tokenized))\n",
        "    return [token.lemma_ for token in doc]\n",
        "\n",
        "# text is lemmatized, filtered, and tokenized\n",
        "def mostCommon(texts, N):\n",
        "    vocab = []\n",
        "    for text in texts:\n",
        "        tokenized = lemmatize(filterTokens(myTokenizer(text)))\n",
        "        vocab.extend(tokenized)\n",
        "    \n",
        "    freqdist = nltk.FreqDist(vocab) \n",
        "    freqdist = freqdist.most_common()\n",
        "    return freqdist[:N]\n",
        "\n",
        "def processSents(text):  # return [(sent, word_count)]\n",
        "    sents = sent_tokenizer.tokenize(text)\n",
        "    return [(sent, len(sent.split())) for sent in sents]\n",
        "\n",
        "def getEntities(text):\n",
        "    doc = nlp(text)\n",
        "    \n",
        "    summary = {}\n",
        "    entities = {}\n",
        "    # orgs = []\n",
        "    # persons = []\n",
        "    # gpes = []\n",
        "    # other = []\n",
        "    for ent in doc.ents:\n",
        "        # 1 build summary of all entities\n",
        "        if ent in summary:\n",
        "            summary[\"ent_cnt(\" + ent.label_ + \")\"] += 1\n",
        "        else:\n",
        "            summary[\"ent_cnt(\" + ent.label_ + \")\"] = 1\n",
        "            \n",
        "        entities[\"contains_entity(\" + ent.text +\")\"] = True\n",
        "        # # 2 get list of orgs mentioned\n",
        "        # if (ent.label_ == 'ORG'):\n",
        "        #     orgs.append(ent.text)\n",
        "        # # 3 get list of people mentioned\n",
        "        # elif (ent.label_ == 'PERSON'):\n",
        "        #     persons.append(ent.text)\n",
        "        # elif (ent.label_ == 'GPE'):\n",
        "        #     gpes.append(ent.text)            \n",
        "        # else:\n",
        "        #     other.append(ent.text)\n",
        "    # return summary, orgs, persons, gpes, other\n",
        "    return summary, entities\n",
        "\n",
        "    \n",
        "# Extract features of a single text\n",
        "def processText(text):\n",
        "    features = {}\n",
        "\n",
        "    if (PREPROCESS_STAGE):\n",
        "        cleaned = lemmatize(filterTokens(myTokenizer(text)))        \n",
        "        svs = speakerVocabScore(cleaned, num_of_speakers, TOP_VOCAB)\n",
        "        features.update(svs)\n",
        "\n",
        "    sent_lengths = [sent[1] for sent in processSents(text)]\n",
        "    avg_sent = sum(sent_lengths) / len(sent_lengths)\n",
        "    features['avg_sent'] = avg_sent\n",
        "\n",
        "    summary, entities = getEntities(text)\n",
        "    features.update(summary)\n",
        "    features.update(entities)\n",
        "    \n",
        "    return features\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# Extract additional features using the training set\n",
        "# - this takes about 2 minutes to do\n",
        "# -------------------------------------------------------------------------\n",
        "# given a speaker and dataset, returns a list of corresponding texts\n",
        "def getSpeakerTexts(speaker, data):\n",
        "    print('Speaker ', speaker, ' - total texts: ', len(data[data.full_name == speaker]['text']))\n",
        "    return data[data.full_name == speaker]['text']\n",
        "\n",
        "# Process the train data and create more features\n",
        "def preprocessSpeakers(speakers, train_data, label_encoder):\n",
        "    if (PREPROCESS_STAGE == False):\n",
        "        return []\n",
        "\n",
        "    speakers_summary = []\n",
        "    for name in speakers:\n",
        "        texts = getSpeakerTexts(name, train_data)\n",
        "        most_common = mostCommon(texts, 25)\n",
        "        speakers_summary.append({\n",
        "                                'ID': label_encoder.transform([name])[0],\n",
        "                                'name':name,\n",
        "                                'top_N_vocab':[tup[0] for tup in most_common]\n",
        "        })\n",
        "\n",
        "    return speakers_summary\n",
        "\n",
        "# This feature requires a prebuilt summary of the speakers (See preprocessSpeakers(...))\n",
        "def speakerVocabScore(tokenized, num_speakers, vocab_lookup):    \n",
        "    if (PREPROCESS_STAGE == False):\n",
        "         return {}\n",
        "\n",
        "    score_table = {}    # {speaker_id : score}\n",
        "\n",
        "    # rally up score\n",
        "    for word in tokenized:\n",
        "        if word in vocab_lookup:                    # this word in the top vocab\n",
        "            for speakerID in vocab_lookup[word]:    # add score to the speaker\n",
        "                if speakerID in score_table:\n",
        "                    score_table[\"SVS_\" + str(speakerID)] += 1  # SVS - speaker_vocab score\n",
        "                else:\n",
        "                    score_table[\"SVS_\" + str(speakerID)] = 1\n",
        "    return score_table\n",
        "# -------------------------------------------------------------------------\n",
        "# -------------------------------------------------------------------------\n",
        "\n"
      ],
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awLREm8whWGJ",
        "colab_type": "text"
      },
      "source": [
        "##Split training/testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvGE5dAGDHt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# train/test data will only be from the sample-size\n",
        "def split_train_test(data, splitpt, sample_size = 1.0):    \n",
        "    length = len(data)\n",
        "    rand_df = pd.DataFrame(np.random.randn(length,2))\n",
        "    msk = np.random.rand(len(rand_df)) < splitpt    \n",
        "\n",
        "    train = data[msk]\n",
        "    old_len = len(train)\n",
        "    train = train.sample(frac=sample_size, replace=False)    \n",
        "    # print(\"train: old_length = \", old_len, \" new_length = \", len(train))\n",
        "    \n",
        "    test = data[~msk]\n",
        "    old_len = len(test)\n",
        "    test = test.sample(frac=sample_size, replace=False)\n",
        "    # print(\"test: old_length = \", old_len, \" new_length = \", len(test))\n",
        "    return train, test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eefZboI4Bm3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.DataFrame(columns = df_top_N.columns)\n",
        "test_df = pd.DataFrame(columns = df_top_N.columns)\n",
        "\n",
        "for name in top_N_speakers:\n",
        "    temp_df = df_top_N[df_top_N.full_name == name]  # only one speaker\n",
        "\n",
        "    train, test = split_train_test(temp_df, 0.8, .25)\n",
        "    train_df = pd.concat([train_df, train])\n",
        "    test_df = pd.concat([test_df, test])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBwJE9jiBT3i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "99b1080c-1564-402d-a874-81034ca3deb5"
      },
      "source": [
        "print(len(X_train))"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwKwjDKXGdcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelencoder = LabelEncoder()\n",
        "\n",
        "X_train = train_df['text']\n",
        "y_train = labelencoder.fit_transform(train_df['full_name'])\n",
        "\n",
        "X_test = test_df['text']\n",
        "y_test = labelencoder.transform(test_df['full_name'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odat-YNHcsb0",
        "colab_type": "text"
      },
      "source": [
        "##Pre-processing stage\n",
        "Extract features from the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Te8UhLRBpUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PREPROCESS_STAGE = True\n",
        "TOP_VOCAB = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPtaiqWBfiOt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "outputId": "f14ff500-d9ab-44c4-a744-493fb483bf14"
      },
      "source": [
        "if (PREPROCESS_STAGE):\n",
        "    SPEAKER_SUMMARY = preprocessSpeakers(top_N_speakers, df_top_N, labelencoder)\n",
        "    num_of_speakers = len(SPEAKER_SUMMARY)\n",
        "\n",
        "    # save time checking if a word is in a speaker's top vocab with this\n",
        "    for i in range(0, num_of_speakers):\n",
        "        for word in SPEAKER_SUMMARY[i]['top_N_vocab']:\n",
        "            if word not in TOP_VOCAB:\n",
        "                TOP_VOCAB[word] = [SPEAKER_SUMMARY[i]['ID']]\n",
        "            else:\n",
        "                # print(word, \":\", TOP_VOCAB[word])\n",
        "                TOP_VOCAB[word].append(SPEAKER_SUMMARY[i]['ID'])            \n"
      ],
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Speaker  Picker Michael  - total texts:  414\n",
            "Speaker  Lara Ricardo  - total texts:  1061\n",
            "Speaker  Secretary Committee  - total texts:  897\n",
            "Speaker  Mullin Kevin  - total texts:  668\n",
            "Speaker  Pan Richard  - total texts:  375\n",
            "Speaker  De Leon Kevin  - total texts:  377\n",
            "Speaker  Chiu David  - total texts:  433\n",
            "Speaker  Beall Jim  - total texts:  317\n",
            "Speaker  Frazier Jim  - total texts:  500\n",
            "Speaker  Hernandez Ed  - total texts:  516\n",
            "Speaker  Bonta Rob  - total texts:  346\n",
            "Speaker  Hueso Ben  - total texts:  363\n",
            "Speaker  Cooley Ken  - total texts:  291\n",
            "Speaker  Jones-Sawyer Reginald  - total texts:  225\n",
            "Speaker  Mitchell Holly  - total texts:  397\n",
            "Speaker  Cappio Claudia  - total texts:  254\n",
            "Speaker  Hertzberg Robert  - total texts:  188\n",
            "Speaker  Thurmond Tony  - total texts:  181\n",
            "Speaker  Eggman Susan Talamantes  - total texts:  167\n",
            "Speaker  Boatman Patterson Tia  - total texts:  124\n",
            "Speaker  Hill Jerry  - total texts:  204\n",
            "Speaker  Lund Jay  - total texts:  150\n",
            "Speaker  Chau Ed  - total texts:  330\n",
            "Speaker  Quirk Bill  - total texts:  222\n",
            "Speaker  Kelly Brian  - total texts:  136\n",
            "Speaker  Wong-Hernandez Jacqueline  - total texts:  176\n",
            "Speaker  DOF Unidentified  - total texts:  189\n",
            "Speaker  Stivers Mark  - total texts:  86\n",
            "Speaker  Stone Jeff  - total texts:  202\n",
            "Speaker  Alejo Luis  - total texts:  154\n",
            "Speaker  Lipman Timothy  - total texts:  126\n",
            "Speaker  Jackson Hannah-Beth  - total texts:  155\n",
            "Speaker  Wagner Donald  - total texts:  132\n",
            "Speaker  Bloom Richard  - total texts:  134\n",
            "Speaker  McCarty Kevin  - total texts:  256\n",
            "Speaker  Liu Carol  - total texts:  396\n",
            "Speaker  Nielsen Jim  - total texts:  151\n",
            "Speaker  Bates Pat  - total texts:  164\n",
            "Speaker  Zuckerman Thomas M.  - total texts:  104\n",
            "Speaker  Agrawal Asha  - total texts:  126\n",
            "Speaker  Gatto Mike  - total texts:  180\n",
            "Speaker  Marcus Felicia  - total texts:  104\n",
            "Speaker  Roth Richard  - total texts:  164\n",
            "Speaker  Speaker Unidentified  - total texts:  178\n",
            "Speaker  Earp Jim  - total texts:  96\n",
            "Speaker  Fuller Jean  - total texts:  145\n",
            "Speaker  Weber Shirley  - total texts:  104\n",
            "Speaker  Cervinka Pete  - total texts:  139\n",
            "Speaker  Gallagher James  - total texts:  105\n",
            "Speaker  Keck Steven  - total texts:  86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfxVjRFxpSNf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "8048dd60-8554-4b84-8464-6b09c1c49eb9"
      },
      "source": [
        "sample = \"And are the sole producer of 14 commodities in California. Including walnuts, which my family grows. And other products such as almonds and raisins. California's agricultural exports totaled $21 billion in 2013, representing 15% of the nation's total. What those figures show, is that farmers and ranchers are adapting.\"\n",
        "processText(sample)"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'SVS_1': 1,\n",
              " 'SVS_11': 1,\n",
              " 'SVS_13': 1,\n",
              " 'SVS_15': 1,\n",
              " 'SVS_17': 1,\n",
              " 'SVS_18': 1,\n",
              " 'SVS_19': 1,\n",
              " 'SVS_2': 1,\n",
              " 'SVS_21': 1,\n",
              " 'SVS_24': 1,\n",
              " 'SVS_27': 1,\n",
              " 'SVS_3': 1,\n",
              " 'SVS_31': 1,\n",
              " 'SVS_33': 1,\n",
              " 'SVS_4': 1,\n",
              " 'SVS_42': 1,\n",
              " 'SVS_44': 1,\n",
              " 'SVS_5': 1,\n",
              " 'SVS_8': 1,\n",
              " 'avg_sent': 9.8,\n",
              " 'contains_entity($21 billion)': True,\n",
              " 'contains_entity(14)': True,\n",
              " 'contains_entity(15%)': True,\n",
              " 'contains_entity(2013)': True,\n",
              " 'contains_entity(California)': True,\n",
              " 'ent_cnt(CARDINAL)': 1,\n",
              " 'ent_cnt(DATE)': 1,\n",
              " 'ent_cnt(GPE)': 1,\n",
              " 'ent_cnt(MONEY)': 1,\n",
              " 'ent_cnt(PERCENT)': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 317
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYiOq_kv4JYf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "510194d3-e278-4b97-835c-f9fac955ef66"
      },
      "source": [
        "len(X_train)"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10536"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiVpR8tw3Wsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Vectorize features\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "vectorizer = DictVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(map(processText, list(X_train)))\n",
        "X_test_vec = vectorizer.transform(map(processText, list(X_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwXQ1YJL3xNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "### Build model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB()\n",
        "model = model.fit(X_train_vec , y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSyxJTZw3yUN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "c7cf261b-6d74-4853-aad7-5f1d65819312"
      },
      "source": [
        "\n",
        "### Accuracy Score\n",
        "print(\"Accuracy Scores:\")\n",
        "print(\"train: \", model.score(X_train_vec, y_train))\n",
        "print(\"test:\", model.score(X_test_vec, y_test))\n",
        "print(\"\\n\\n\")"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Scores:\n",
            "train:  0.20418442464161177\n",
            "test: 0.17602427921092564\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}